{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf58756-1320-472a-9a30-beb68bbc7ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ./checkpoints/beamvq_reconstruction_v1_best_model.pth\n",
      "Starting inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference: 100%|█████████████████████████████████████████████████████████████████████████| 366/366 [02:34<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed. Results saved to ./results\n",
      "Average VQ Loss: 0.00000041711566\n",
      "Reconstruction MSE: 0.00001372790211\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader_rec import ClimateReconstructionDataset\n",
    "from generative_world_model import Generative_World_Model\n",
    "\n",
    "# Configuration\n",
    "backbone = 'beamvq_reconstruction_v1'\n",
    "DATA_DIR = \"/jizhicfs/easyluwu/scaling_law/ft_local/low_res\"\n",
    "CHECKPOINT_PATH = f'./checkpoints/{backbone}_best_model.pth'\n",
    "RESULT_DIR = './results'\n",
    "BATCH_SIZE = 3\n",
    "VARIABLES = range(69)  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "model = BeamVQ(\n",
    "    in_channel=69,\n",
    "    res_layers=2,\n",
    "    embedding_nums=1024, \n",
    "    embedding_dim=256,\n",
    "    top_k=10).to(device)\n",
    "\n",
    "# Load checkpoint with proper handling of DDP prefix\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    # Load the state dict\n",
    "    state_dict = torch.load(CHECKPOINT_PATH, map_location=device, weights_only=True)\n",
    "    \n",
    "    # Remove 'module.' prefix from keys if present\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith('module.'):\n",
    "            new_state_dict[k[7:]] = v  # remove 'module.' prefix\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "    \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    print(f\"Loaded model from {CHECKPOINT_PATH}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Checkpoint not found at {CHECKPOINT_PATH}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Create test dataset and loader\n",
    "test_dataset = ClimateReconstructionDataset(\n",
    "    data_path=DATA_DIR,\n",
    "    years=range(2019, 2022),  # Using test years\n",
    "    variables=VARIABLES\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# Inference function\n",
    "def run_inference(model, test_loader, device):\n",
    "    all_inputs = []\n",
    "    all_targets = []\n",
    "    all_outputs = []\n",
    "    all_vq_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Running inference\"):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            pred, _, vq_loss = model(inputs)\n",
    "            \n",
    "            # Collect results\n",
    "            all_inputs.append(inputs.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "            all_outputs.append(pred.cpu().numpy())\n",
    "            all_vq_losses.append(vq_loss.item())\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_inputs = np.concatenate(all_inputs, axis=0)\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "    all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "    avg_vq_loss = np.mean(all_vq_losses)\n",
    "    \n",
    "    return all_inputs, all_targets, all_outputs, avg_vq_loss\n",
    "\n",
    "# Run inference\n",
    "print(\"Starting inference...\")\n",
    "inputs, targets, outputs, avg_vq_loss = run_inference(model, test_loader, device)\n",
    "\n",
    "# Save results\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "np.save(f'{RESULT_DIR}/{backbone}_inputs.npy', inputs)\n",
    "np.save(f'{RESULT_DIR}/{backbone}_targets.npy', targets)\n",
    "np.save(f'{RESULT_DIR}/{backbone}_outputs.npy', outputs)\n",
    "\n",
    "print(f\"Inference completed. Results saved to {RESULT_DIR}\")\n",
    "print(f\"Average VQ Loss: {avg_vq_loss:.14f}\")\n",
    "\n",
    "# Calculate MSE\n",
    "mse = np.mean((targets - outputs) ** 2)\n",
    "print(f\"Reconstruction MSE: {mse:.14f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47696a0-4f33-4737-bd5d-c3529d73e3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d2ad4b-ee77-40ea-992a-c6300163677a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
